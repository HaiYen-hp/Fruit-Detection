{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install tensorflow","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install --user matplotlib==3.5.0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sn\nimport os\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nfrom tensorflow.keras.optimizers import Adadelta\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n\n\n##############################################\nlearning_rate = 0.1  # khoi tao learning rate\nmin_learning_rate = 0.00001  # khi learning rate dat den gia tri nay, khong giam them\nlearning_rate_reduction_factor = 0.5  # he so duoc su dung khi giam learning rate -> learning_rate *= learning_rate_reduction_factor\npatience = 3  # can cho bao nhieu so vong lap truoc khi giam learning rate khi do mat mat len cao (loss len cao)\nverbose = 1  # kiem soat so lan chay duoc thuc hien trong qua trinh dao tao va thuc nghiem: 0 - none, 1 - bao cao so lieu sau moi batch, 2 - bao cao so lieu sau moi vong lap\nimage_size = (100, 100)  # chieu dai va chieu rong cua anh\ninput_shape = (100, 100, 3)  # hinh dang dau vao du kien cho cac mo hinh duoc dao tao; vi hinh anh trong Fruit-360 la hinh anh RGB 100 x 100, day la hinh dang dau vao bat buoc\n\nuse_label_file = False  # dat bien nay thanh true neu ban muon tai ten nhan tu tep; tep phai chua ten cua cac nhan da su dung, moi nhan tren moi dong rieng biet\nlabel_file = 'labels.txt'\nbase_dir = 'E:\\\\files for study\\\\AI\\\\ML\\\\Assignment2\\\\Fruit-Images-Dataset-master' # duong dan toi thu muc chua tap du lieu hoa qua\ntest_dir = os.path.join(base_dir, 'Test')\ntrain_dir = os.path.join(base_dir, 'Training')\noutput_dir = 'E:\\\\files for study\\\\AI\\\\ML\\\\Assignment2\\\\Ketqua'  # thu muc goc de luu cac tep dau ra\n##############################################\n\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\nif use_label_file:\n    with open(label_file, \"r\") as f:\n        labels = [x.strip() for x in f.readlines()]\nelse:\n    labels = os.listdir(train_dir)\nnum_classes = len(labels)\n\n# tao 2 bieu do, mot cho do chinh xac, 1 cho ham mat mat, de hien thi so lieu cau hai chi so nay trong qua trinh dao tao\ndef plot_model_history(model_history, out_path=\"\"):\n    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n    # do chinh xac\n    axs[0].plot(range(1, len(model_history.history['accuracy']) + 1), model_history.history['accuracy'])\n    axs[0].plot(range(1, len(model_history.history['val_accuracy']) + 1), model_history.history['val_accuracy'])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    #axs[0].set_xticks(np.arange(1, len(model_history.history['accuracy']) + 1), model_history.history['accuracy'])\n    axs[0].legend(['train', 'val'], loc='best')\n    # ham mat mat\n    axs[1].plot(range(1, len(model_history.history['loss']) + 1), model_history.history['loss'])\n    axs[1].plot(range(1, len(model_history.history['val_loss']) + 1), model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    #axs[1].set_xticks(np.arange(1, len(model_history.history['loss']) + 1), model_history.history['loss'])\n    axs[1].legend(['train', 'val'], loc='best')\n    # luu bieu do trong mot file goi la \"acc_loss.png\";model_name duoc cung cap khi tao va dao tao mo hinh\n    if out_path:\n        plt.savefig(out_path + \"/acc_loss.png\")\n    plt.show()\n\n\n# tao mot ma tran nham lan de hien thi cac anh dan nham nhan\ndef plot_confusion_matrix(y_true, y_pred, classes, out_path=\"\"):\n    cm = confusion_matrix(y_true, y_pred)\n    df_cm = pd.DataFrame(cm, index=[i for i in classes], columns=[i for i in classes])\n    plt.figure(figsize=(40, 40))\n    ax = sn.heatmap(df_cm, annot=True, square=True, fmt=\"d\", linewidths=.2, cbar_kws={\"shrink\": 0.8})\n    if out_path:\n        plt.savefig(out_path + \"/confusion_matrix.png\")  # ma tran duoc l∆∞u vao 1 file ten la \"model_name_confusion_matrix.png\"\n    return ax\n\n\n# Thay doi ngau nhien mau sac va do bao hoa cua hinh anh de mo phong cac dieu kien anh sang thay doi \ndef augment_image(x):\n    import tensorflow as tf\n    x = tf.image.random_saturation(x, 0.9, 1.2)\n    x = tf.image.random_hue(x, 0.02)\n    return x\n\n# dua ra  duong dan chua thu muc train va thu muc tap test, va ty le xac thu de kiem tra, can truyen vao 3 trinh tao\n#  - trinh tao tap train su dung (100 - validation_percent) phan tram cua hinh anh tu tap train \n#    ap dung lat ngang va lat doc ngau nhien de tang du lieu va tao cac batch mot cac ngau nhien\n#  - trinh tao validation su dung validation_percent con lai cau hinh anh lay tu tap train\n#    khong tao ra cac batch ngau nhien, vi mo hinh khong duoc dao tao ve du lieu nay\n#    do chinh xac va mat mat duoc theo doi bang cach su dung du lieu validation de co the cap nhap toc do hoc neu mo hinh dat muc toi uu cuc bo\n#  - trinh tao tap test su dung tap test ma khong co bat ky hinh thuc gia tang nao\n#    mot khi qua trinh huan luyen duoc thuc hien cac gia tri cuoi cung cua do chinh xac va mat mat duoc tinh toan\ndef build_data_generators(train_folder, test_folder, validation_percent, labels=None, image_size=(100, 100), batch_size=50):\n    train_datagen = ImageDataGenerator(\n        width_shift_range=0.0,\n        height_shift_range=0.0,\n        zoom_range=0.0,\n        horizontal_flip=True,\n        vertical_flip=True,  # lat ngau nhien\n        preprocessing_function=augment_image, \n        validation_split=validation_percent)  # ty le phan tram cho biet so luong tap hop dao tao nen duoc giu lai de xac thuc, cho vao tap validation\n\n    test_datagen = ImageDataGenerator()\n\n    train_gen = train_datagen.flow_from_directory(train_folder, target_size=image_size, class_mode='sparse',\n                                                  batch_size=batch_size, shuffle=True, subset='training', classes=labels)\n    validation_gen = train_datagen.flow_from_directory(train_folder, target_size=image_size, class_mode='sparse',\n                                                       batch_size=batch_size, shuffle=False, subset='validation', classes=labels)\n    test_gen = test_datagen.flow_from_directory(test_folder, target_size=image_size, class_mode='sparse',\n                                                batch_size=batch_size, shuffle=False, subset=None, classes=labels)\n    return train_gen, validation_gen, test_gen\n\n\n# phuong phap nay thuc hien tat ca cac buoc tu thiet lap du lieu, dao tao va thu nghiem mo hinh, ve bieu do ket qua\n# mo hinh la mot mo hinh bat ky co the dao tao; hinh dang dau vao va so luong dau ra cua cac lop phu thuoc vao tap du lieu duoc su dung, \n# trong truong hop nay dau vao la hinh anh RGB 100 x 100 va dau ra la lop softmax voi 118 xac suat\n# ten duoc su dung de luu bao cao phan loai co chua diem f1 cua mo hinh, cac bieu do hien thi do mat mat va do chinh xac va ma tran nham lan\n# kich thuoc batch duoc su dung de xac dinh so luong hinh anh duoc truyen qua mang CNN cung 1 luc, so buoc tren moi vong lap duoc tinh tu day la (tong so hinh anh trong bo / kich thuoc lo)+1\ndef train_and_evaluate_model(model, name=\"\", epochs=25, batch_size=50, verbose=verbose, useCkpt=False):\n    print(model.summary())\n    model_out_dir = os.path.join(output_dir, name)\n    if not os.path.exists(model_out_dir):\n        os.makedirs(model_out_dir)\n    if useCkpt:\n        model.load_weights(model_out_dir + \"/model.h5\")\n\n    trainGen, validationGen, testGen = build_data_generators(train_dir, test_dir, validation_percent=0.1, labels=labels, image_size=image_size, batch_size=batch_size)\n    optimizer = Adadelta(lr=learning_rate)\n    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n    learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=patience, verbose=verbose, \n                                                factor=learning_rate_reduction_factor, min_lr=min_learning_rate)\n    save_model = ModelCheckpoint(filepath=model_out_dir + \"/model.h5\", monitor='val_accuracy', verbose=verbose, \n                                 save_best_only=True, save_weights_only=False, mode='max', period=1)\n    \n    history = model.fit(trainGen,\n                                  epochs=epochs,\n                                  steps_per_epoch=(trainGen.n // batch_size) + 1,\n                                  validation_data=validationGen,\n                                  validation_steps=(validationGen.n // batch_size) + 1,\n                                  verbose=verbose,\n                                  callbacks=[learning_rate_reduction, save_model])\n\n    model.load_weights(model_out_dir + \"/model.h5\")\n\n    validationGen.reset()\n    loss_v, accuracy_v = model.evaluate(validationGen, steps=(validationGen.n // batch_size) + 1, verbose=verbose)\n    loss, accuracy = model.evaluate(testGen, steps=(testGen.n // batch_size) + 1, verbose=verbose)\n    print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (accuracy_v, loss_v))\n    print(\"Test: accuracy = %f  ;  loss_v = %f\" % (accuracy, loss))\n    plot_model_history(history, out_path=model_out_dir)\n    testGen.reset()\n    y_pred = model.predict(testGen, steps=(testGen.n // batch_size) + 1, verbose=verbose)\n    y_true = testGen.classes[testGen.index_array]\n    plot_confusion_matrix(y_true, y_pred.argmax(axis=-1), labels, out_path=model_out_dir)\n    class_report = classification_report(y_true, y_pred.argmax(axis=-1), target_names=labels)\n\n    with open(model_out_dir + \"/classification_report.txt\", \"w\") as text_file:\n        text_file.write(\"%s\" % class_report)\n    # print(class_report)\n\n\nprint(labels)\nprint(num_classes)","metadata":{"pycharm":{"is_executing":false,"name":"#%%\n"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Activation, Dropout, Lambda\n\n\n# Tao mot lop tuy chinh de chuyen doi hinh anh goc tu \n# RGB sang HSV va thang do xam va noi cac ket qua  \n# tao hinh o dau vao co kich thuoc 100 x 100 x 4\ndef convert_to_hsv_and_grayscale(x):\n    import tensorflow as tf\n    hsv = tf.image.rgb_to_hsv(x)\n    gray = tf.image.rgb_to_grayscale(x)\n    rez = tf.concat([hsv, gray], axis=-1)\n    return rez\n\n\ndef network(input_shape, num_classes):\n    img_input = Input(shape=input_shape, name='data')\n    x = Lambda(convert_to_hsv_and_grayscale)(img_input)\n    x = Conv2D(16, (5, 5), strides=(1, 1), padding='same', name='conv1')(x)\n    x = Activation('relu', name='conv1_relu')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool1')(x)\n    x = Conv2D(64, (5, 5), strides=(1, 1), padding='same', name='conv2')(x)\n    x = Activation('relu', name='conv2_relu')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool2')(x)\n    x = Conv2D(64, (5, 5), strides=(1, 1), padding='same', name='conv3')(x)\n    x = Activation('relu', name='conv3_relu')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool3')(x)\n    x = Conv2D(128, (5, 5), strides=(1, 1), padding='same', name='conv4')(x)\n    x = Activation('relu', name='conv4_relu')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool4')(x)\n    x = Flatten()(x)\n    x = Dense(1024, activation='relu', name='fcl1')(x)\n    x = Dropout(0.2)(x)\n    x = Dense(256, activation='relu', name='fcl2')(x)\n    x = Dropout(0.2)(x)\n    out = Dense(num_classes, activation='softmax', name='predictions')(x)\n    rez = Model(inputs=img_input, outputs=out)\n    return rez\n\n\nmodel = network(input_shape=input_shape, num_classes=num_classes)\ntrain_and_evaluate_model(model, name=\"fruit-360 model\")","metadata":{"pycharm":{"is_executing":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}